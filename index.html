<!DOCTYPE html>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XB3PR2Y1TQ"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XB3PR2Y1TQ');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>RaBit: Parametric Modeling of 3D Biped Cartoon Characters with a Topological-consistent Dataset</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="./assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="./assets/css/styles.css">

    <link rel="apple-touch-icon" sizes="180x180" href="./apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./favicon-16x16.png">
    <link rel="manifest" href="./site.webmanifest">

    <meta property="og:site_name" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta property="og:type" content="video.other" />
    <meta property="og:title" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta property="og:description" content="DreamFusion: Text-to-3D using 2D Diffusion, 2022." />
    <meta property="og:url" content="https://dreamfusion3d.github.io/" />
    <meta property="og:image" content="https://dreamfusion3d.github.io/assets/images/dreamfusion_samples.png" />

    <meta property="article:publisher" content="https://dreamfusion3d.github.io/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta name="twitter:description" content="We combine neural rendering with a multi-modal text-to-2D image diffusion generative model to synthesize diverse 3D objects from text." />
    <meta name="twitter:url" content="https://dreamfusion3d.github.io/" />
    <meta name="twitter:image" content="https://dreamfusion3d.github.io/assets/images/dreamfusion_samples.png" />
    <!-- <meta name="twitter:site" content="" /> -->

    <script src="./assets/js/video_comparison.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script>
</head>

<body>
    <div class="banner">
    
    <!--
      <video class="video lazy"
          poster="https://dreamfusion-cdn.ajayj.com/sept28/banner_1x6_customhue_A.jpg"
          autoplay loop playsinline muted>
        <source data-src="https://dreamfusion-cdn.ajayj.com/sept28/banner_1x6_customhue_A.mp4" type="video/mp4"></source>
      </video> 
    -->

    <img src='./assets/images/fig_teaser3.png' width="1000px"/>
    
    </div>
    <div class="highlight-clean" style="padding-bottom: 10px;">
        <div class="container" style="max-width: 768px;">
            <h1 class="text-center"><i>RaBit</i>: Parametric Modeling of 3D Biped Cartoon Characters with a Topological-consistent Dataset</h1>
        </div>
        <div class="container" style="max-width: 768px;">
            <div class="row authors">
                <!--  template
                <div class="col-sm-3">
                    <h5 class="text-center"><a href="https://ajayj.com">Shengcai Cai</a></h5>
                    <h6 class="text-center">CUHK(SZ) Gap Lab</h6>
                </div>
                -->
                <div class="col-sm-3">
                    <h5 class="text-center">Zhongjin Luo*</h5>
                    <h6 class="text-center"><a href="https://gaplab.cuhk.edu.cn/">CUHK(SZ) Gap Lab</a></h6>
                </div>
                <div class="col-sm-3">
                    <h5 class="text-center">Shengcai Cai*</h5>
                    <h6 class="text-center"><a href="https://gaplab.cuhk.edu.cn/">CUHK(SZ) Gap Lab</a></h6>
                </div>
                <div class="col-sm-3">
                    <h5 class="text-center">Jinguo Dong</h5>
                    <h6 class="text-center"><a href="https://gaplab.cuhk.edu.cn/">CUHK(SZ) Gap Lab</a></h6>
                </div>
                <div class="col-sm-3">
                    <h5 class="text-center">Ruibo Ming</h5>
                    <h6 class="text-center">Tsinghua University</h6>
                </div>
                <div class="col-sm-3">
                    <h5 class="text-center">Liangdong Qiu</h5>
                    <h6 class="text-center"><a href="https://gaplab.cuhk.edu.cn/">CUHK(SZ) Gap Lab</a></h6>
                </div>
                <div class="col-sm-3">
                    <h5 class="text-center">Xiaohang Zhan</h5>
                    <h6 class="text-center">Huawei</h6>
                </div>
                <div class="col-sm-3">
                    <h5 class="text-center">Xiaoguang Han#</h5>
                    <h6 class="text-center">CUHK(SZ) Gap Lab</h6>
                </div>
            </div>    
        </div>
        <div class="buttons" style="margin-bottom: 8px;">
            <a class="btn btn-light disabled border border-dark" role="button" aria-disabled="true" href="https://arxiv.org/abs/2209.14988">
                <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" viewBox="0 0 24 24">
                    <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z"></path>
                </svg>Paper
            </a>
            <a class="btn btn-light disabled border border-dark" aria-disabled="true" role="button" href="#">
                <svg style="visibility:hidden;width:0px;height:24px;margin-left:-12px;margin-right:12px" width="0px" height="24px" viewBox="0 0 375 531">
                    <polygon stroke="#000000" points="0.5,0.866 459.5,265.87 0.5,530.874 "/>
                </svg>
                Project
            </a>
            <a class="btn btn-light disabled border border-dark" role="button" aria-disabled="true" href="./gallery.html">
                <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" width="24px" height="24px" viewBox="0 0 375 531">
                    <polygon stroke="#000000" points="0.5,0.866 459.5,265.87 0.5,530.874 "/>
                </svg>
                Gallery
            </a>
            <a class="btn btn-light disabled border border-dark" role="button" aria-disabled="true" href="./gallery.html">
                <svg style="visibility:hidden;width:0px;height:24px;margin-left:-12px;margin-right:12px" width="0px" height="24px" viewBox="0 0 375 531">
                    <polygon stroke="#000000" points="0.5,0.866 459.5,265.87 0.5,530.874 "/>
                </svg>
                Data
            </a>

            <!-- template
            <a class="btn btn-light" role="button" aria-disabled="true" href="/gallery.html">
                <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" width="24px" height="24px" viewBox="0 0 375 531">
                    <polygon stroke="#000000" points="0.5,0.866 459.5,265.87 0.5,530.874 "/>
                </svg>
                Gallery
            </a>
            -->
        </div>
    </div>
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Abstract</h2>
                <p>
                    <!-- <strong> -->
                        Assisting people in efficiently producing visually plausible 3D characters has always been a fundamental research topic in computer vision and computer graphics. Recent learning-based approaches have achieved unprecedented accuracy and efficiency in the area of 3D real human digitization. However, none of the prior works focus on modeling 3D biped cartoon characters, which are also in great demand in gaming and filming. In this paper, we introduce 3DBiCar, the first large-scale dataset of 3D biped cartoon characters, and RaBit, the corresponding parametric model. Our dataset contains 1,500 topologically consistent high-quality 3D textured models which are manually crafted by professional artists. Built upon the data, RaBit is thus designed with a SMPL-like linear blend shape model and a StyleGAN-based neural UV-texture generator, simultaneously expressing the shape, pose, and texture. To demonstrate the practicality of 3DBiCar and RaBit, various applications are conducted, including single-view reconstruction, sketch-based modeling, and 3D cartoon animation. For the single-view reconstruction setting, we find a straightforward global mapping from input images to the output UV-based texture maps tends to lose detailed appearances of some local parts (e.g., nose, ears). Thus, a novel part-sensitive texture reasoner is designed to make all important local areas perceived. Experiments further demonstrate the effectiveness of such a novel design, both qualitatively and quantitatively. We will release both 3DBiCar and RaBit to the research community.
                    <!-- </strong> -->
                </p>
            </div>
        </div>
    </div>
    
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <h2>3DBiCar</h2>
        <img src='./assets/images/fig_dataset_gallery.png' width="1000px"/>
        *Each collected reference image is followed by the T-pose model and the posed model, created by professional artists. 3DBiCar contains 1,500 topologically consistent, textured and skinned 3D high-quality models with paired 2D images, which covers 15 species and 4 image styles.
        <p><a href="./gallery.html">Here shows some 3D models in our Dataset.  </a></p>
        <br>
        note:这里指引到dataset 的 gallery        
    </div>
    
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <h2>RaBit</h2>
        <p>With 3DBiCar, we propose the first parametric model of 3D biped cartoon characters (RaBit), which contains a linear blend model for shapes and a neural generator for textures. RaBit simultaneously parameterizes the shape, pose, and texture of the 3D biped character. </p>
        
        <p><font color="#FF0000">split video here?</font></p>
        <p><font color="#FF0000">display some objs here?</font></p>
        <video class="video lazy" controls="" muted="" poster="https://dreamfusion-cdn.ajayj.com/dreamfusion_overview.jpg">
                <source data-src="https://dreamfusion-cdn.ajayj.com/dreamfusion_overview.mp4" type="video/mp4">
        </video>
    </div>
    
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="col-sm-8">
            <h2>Single View Rconstuction</h2>          
        </div>
        <p>Single-view reconstruction (SVR) is one of the most popular tasks of efficient 3D content generation, and recent work has made noticeable progress on human reconstruction based on parametric model of human characters (e.g., SMPL).</p>
        <img src='./assets/images/pipeline_svr_00.png' width="1000px"/>
        *To verify the practicality of our proposed 3DBiCar and RaBit, we present our baseline method <i>BiCarNet</i> for single view reconstruction for bipled cartoon characters
        <img src='./assets/images/wild_result_00.png' width="1000px"/>
        * Our BiCarNet is capable of generating vivid 3D cartoon characters with only single-view image input.
        <p><font color="#FF0000">display impletement video here?</font></p>
            <video class="video lazy" controls="" muted="" poster="https://dreamfusion-cdn.ajayj.com/dreamfusion_overview.jpg">
                <source data-src="https://dreamfusion-cdn.ajayj.com/dreamfusion_overview.mp4" type="video/mp4">
            </video>
        <div class="col-sm-8">
        <p><font color="#FF0000">display some objs here?</font></p>
        </div>
    </div>


    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <h2>More Application</h2>          
        
        <h3>&#9670 Sketch Based Modeling</h3>  
        <img src='./assets/images/sketch_result_00.png' width="1000px"/>
        *The sketch created by amateur users denotes on the left and generated models on the right.
        <p><font color="#FF0000">display some objs here！</font></p>      
        
        <h3>&#9670 Animation</h3>        
        <p> <font color="#FF0000">split video here！</font></p>
        
    </div>


    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Citation</h2>
                <code>
                    TBD(RaBit)

                    <br>
                    <font color="#FF0000">TODO:</font>
                    <br>
                    <font color="#FF0000">1.视频是否要外部引入...（当前视频是临时使用的）</font>
                    <br>
                    <font color="#FF0000">2.obj的使用暂时还没有打穿</font>
                </code>
            </div>
        </div>
    </div>

    <!-- template
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Composing objects into a scene</h2>
                <p>Our generated NeRF models can be exported to meshes using the marching cubes algorithm for easy integration into 3D renderers or modeling software.</p> 
                <video class="video lazy" autoplay loop playsinline controls muted poster="https://dreamfusion-cdn.ajayj.com/carouselx24_128tall.jpg">
                    <source src="https://dreamfusion-cdn.ajayj.com/carouselx24_128tall.mp4" type="video/mp4"></source>
                </video>
            </div>
        </div>
    </div>
    -->




    <script src="https://polyfill.io/v3/polyfill.js?features=IntersectionObserver"></script>
    <script src="./assets/js/yall.js"></script>
    <script>
        yall(
            {
                observeChanges: true
            }
        );
    </script>
    <script src="./assets/js/scripts.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>
    <!-- Import the component -->
</body>

</html>
